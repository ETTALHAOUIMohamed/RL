{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e245b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dbe8b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stateClass:\n",
    "    def __init__(self,state, K, reward = -1):\n",
    "        self.K = K\n",
    "        self.isStart = self.isStart(state)\n",
    "        self.isEnd = self.isTerminal(state)\n",
    "        self.state = state\n",
    "        self.reward = reward\n",
    "    \n",
    "        if (self.state == (self.K-1,self.K-1)):\n",
    "            self.reward = 2*(self.K-1)\n",
    "            \n",
    "    def isTerminal(self, state):\n",
    "        if (state==(self.K-1,self.K-1)):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def isStart(self, state):\n",
    "        if (state==(0,0)):\n",
    "            return True\n",
    "        return False\n",
    "      \n",
    "    def getStates(self):\n",
    "        return (self.state[0],self.state[1])\n",
    "\n",
    "\n",
    "    def getReward(self):\n",
    "        if self.state == (self.K-1,self.K-1):\n",
    "            return 2*(self.K-1)\n",
    "#         elif self.state == LOSE_STATE:\n",
    "#             return -1\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97add84",
   "metadata": {},
   "source": [
    "# epsilon greedy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49b522c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grid_ep():\n",
    "    def __init__(self,K):\n",
    "        self.K = K\n",
    "#         self.grid = np.zeros((self.K,self.K))\n",
    "        self.action_value_state = np.zeros((self.K,self.K))\n",
    "#         self.policy = np.chararray((self.K,self.K)).decode(\"utf-8\")\n",
    "        self.policy = [[\"\" for i in range(self.K)] for i in range(self.K)]\n",
    "        \n",
    "    def q(self, alpha=0.01, num_episodes=300, gamma=0.9,epsilon=0.2):\n",
    "        for ep in range(num_episodes):\n",
    "            init = [i for i in range(self.K)]\n",
    "            m = random.choice(init)\n",
    "            n = random.choice(init)\n",
    "            state=stateClass((m,n),self.K)\n",
    "            while True:\n",
    "                action = self.take_epsilon_greedy_action(state.getStates(),gamma,epsilon)\n",
    "                next_state = self.step(state.getStates(),action)\n",
    "                next_state_ = stateClass(next_state,self.K)\n",
    "                reward = next_state_.getReward()\n",
    "\n",
    "                self.action_value_state[state.getStates()[0]][state.getStates()[1]] += alpha*(reward+gamma*self.action_value_state[next_state[0]][next_state[1]]-self.action_value_state[state.getStates()[0]][state.getStates()[1]])\n",
    "                self.policy[state.getStates()[0]][state.getStates()[1]] = action\n",
    "                state=next_state_\n",
    "                if action == 'T':\n",
    "                    break\n",
    "\n",
    "        return self.action_value_state,self.policy\n",
    "\n",
    "    def take_epsilon_greedy_action(self,state, gamma,epsilon):\n",
    "        if np.random.random() <= epsilon:\n",
    "            return random.choice(self.getPossibleActions(state))\n",
    "        else:\n",
    "\n",
    "            dct={}\n",
    "            possible_actions = self.getPossibleActions(state)\n",
    "            for i, val in enumerate(possible_actions):\n",
    "                if val == ['T']:\n",
    "                    continue\n",
    "                next_state = self.step(state,val)\n",
    "                v_next = self.action_value_state[next_state[0]][next_state[1]]\n",
    "                next_state = stateClass((next_state[0],next_state[1]),self.K)\n",
    "                reward = next_state.reward\n",
    "                v_new = reward + gamma*v_next\n",
    "                dct[val]=v_new\n",
    "\n",
    "            valist = [val for val in dct.values()]\n",
    "            max_value = max(valist)\n",
    "            self.action_value_state[state[0]][state[1]] = max_value\n",
    "            best_action = self.get_best_action(dct,max_value)\n",
    "            return best_action\n",
    "\n",
    "\n",
    "    def step(self, state,action):\n",
    "        i = state[0]\n",
    "        j = state[1]\n",
    "        if action == 'S': # NORTH\n",
    "            if i == self.K-1:\n",
    "                return None\n",
    "            else:\n",
    "                i+=1        \n",
    "          \n",
    "        elif action == 'E':#EAST\n",
    "            if j == self.K-1:\n",
    "                return None\n",
    "            else:\n",
    "                j+=1\n",
    "                        \n",
    "        elif action == 'N':#SUD\n",
    "            if i == 0:\n",
    "                return None\n",
    "            else:\n",
    "                i-=1\n",
    "                                      \n",
    "        elif action == 'W':#WEST\n",
    "            if j == 0:\n",
    "                return None\n",
    "            else:\n",
    "                j-=1\n",
    "            \n",
    "        return (i,j)\n",
    "    \n",
    "    def getPossibleActions(self, state):\n",
    "        \n",
    "        if state[0]==0:\n",
    "            if state[1]==0:\n",
    "                return ['E','S']\n",
    "            elif state[1]==self.K-1:\n",
    "                return ['S','W']\n",
    "            else:\n",
    "                return ['W','E','S']\n",
    "\n",
    "        elif state[0]==self.K - 1:\n",
    "            if state[1]==0:\n",
    "                return ['N','E']\n",
    "            elif state[1]==self.K-1:\n",
    "                return ['T']\n",
    "            \n",
    "            else:\n",
    "                return ['N','E','W']\n",
    "\n",
    "        elif state[1]==0:\n",
    "            return ['S','N','E']\n",
    "        \n",
    "        elif state[1]==self.K-1:\n",
    "            return ['N','S','W']\n",
    "\n",
    "        else:\n",
    "            return ['N','E','S','W']\n",
    "        \n",
    "    def get_best_action(self,d,val):\n",
    "        for key, value in d.items():\n",
    "            if val == value:\n",
    "                return key\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4474341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter k the size of the gridWorld: 12\n"
     ]
    }
   ],
   "source": [
    "k = int(input(\"Enter k the size of the gridWorld: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3b0e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = Grid_ep(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4899b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_value_state,policy = grid.q()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "969c446c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['E', 'E', 'S', 'S', 'S', 'W', 'E', 'E', 'S', 'E', 'S', 'W'],\n",
       " ['S', 'S', 'W', 'E', 'S', 'W', 'S', 'S', 'S', 'W', 'S', 'W'],\n",
       " ['E', 'E', 'E', 'E', 'E', 'E', 'E', 'S', 'S', 'N', 'W', 'W'],\n",
       " ['S', 'S', 'E', 'S', 'W', 'N', 'N', 'E', 'S', 'E', 'S', 'W'],\n",
       " ['E', 'S', 'E', 'E', 'S', 'S', 'W', 'S', 'E', 'N', 'S', 'S'],\n",
       " ['E', 'S', 'W', 'E', 'E', 'S', 'S', 'S', 'S', 'W', 'S', 'W'],\n",
       " ['E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'S', 'S', 'W', 'W'],\n",
       " ['N', 'S', 'N', 'E', 'S', 'E', 'E', 'E', 'E', 'S', 'S', 'S'],\n",
       " ['N', 'E', 'S', 'E', 'E', 'E', 'E', 'E', 'S', 'S', 'S', 'W'],\n",
       " ['E', 'E', 'E', 'E', 'S', 'E', 'E', 'S', 'S', 'W', 'E', 'S'],\n",
       " ['E', 'N', 'E', 'E', 'S', 'S', 'E', 'S', 'E', 'S', 'W', 'S'],\n",
       " ['N', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'T']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "813051a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_policy():\n",
    "    init = [i for i in range(12)]\n",
    "    m = random.choice(init)\n",
    "    n = random.choice(init)\n",
    "    l = []\n",
    "    start = (m,n)\n",
    "    print(f\"starting from {start} follow this path\")\n",
    "    l.append(policy[m][n])\n",
    "    while(policy[m][n]!='T'):\n",
    "        if policy[m][n]=='E':\n",
    "            n+=1\n",
    "            l.append(policy[m][n])\n",
    "        elif policy[m][n]=='W':\n",
    "            n-=1\n",
    "            l.append(policy[m][n])\n",
    "        elif policy[m][n]=='S':\n",
    "            m+=1\n",
    "            l.append(policy[m][n])\n",
    "        elif policy[m][n]=='N':\n",
    "            m-=1\n",
    "            l.append(policy[m][n])\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63e36ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting from (7, 3) follow this path\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['E', 'S', 'E', 'E', 'E', 'E', 'S', 'S', 'E', 'S', 'E', 'E', 'T']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "road = print_policy()\n",
    "road"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d777bfb2",
   "metadata": {},
   "source": [
    "# greedy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0f85c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#without epsilon greedy\n",
    "class Grid():\n",
    "    def __init__(self,K):\n",
    "        self.K = K\n",
    "        self.action_value_state = np.zeros((self.K,self.K))\n",
    "        self.policy = [[\"\" for i in range(self.K)] for i in range(self.K)]\n",
    "        \n",
    "    def q(self, alpha=0.01, num_episodes=300, gamma=0.9):\n",
    "        for ep in range(num_episodes):\n",
    "            init = [i for i in range(self.K)]\n",
    "            m = random.choice(init)\n",
    "            n = random.choice(init)\n",
    "            state=stateClass((m,n),self.K)\n",
    "            while True:\n",
    "                action = self.take_greedy_action(state.getStates())\n",
    "                next_state = self.step(state.getStates(),action)\n",
    "                next_state_ = stateClass(next_state,self.K)\n",
    "                reward = next_state_.reward\n",
    "                self.action_value_state[state.getStates()[0]][state.getStates()[1]] += alpha*(reward+gamma*self.action_value_state[next_state[0]][next_state[1]]-self.action_value_state[state.getStates()[0]][state.getStates()[1]])\n",
    "                self.policy[state.getStates()[0]][state.getStates()[1]] = action\n",
    "                state=next_state_\n",
    "                if action == 'T':\n",
    "                    break\n",
    "\n",
    "        return self.action_value_state,self.policy\n",
    "\n",
    "    def take_greedy_action(self,state, gamma=0.9):\n",
    "        dct={}\n",
    "        possible_actions = self.getPossibleActions(state)\n",
    "        for i, val in enumerate(possible_actions):\n",
    "            if val == ['T']:\n",
    "                continue\n",
    "            next_state = self.step(state,val)\n",
    "            v_next = self.action_value_state[next_state[0]][next_state[1]]\n",
    "            next_state = stateClass((next_state[0],next_state[1]),self.K)\n",
    "            reward = next_state.reward\n",
    "            v_new = reward + gamma*v_next\n",
    "            dct[val]=v_new\n",
    "\n",
    "        valist = [val for val in dct.values()]\n",
    "        max_value = max(valist)\n",
    "        self.action_value_state[state[0]][state[1]] = max_value\n",
    "        best_action = self.get_best_action(dct,max_value)\n",
    "        return best_action\n",
    "\n",
    "\n",
    "    def step(self, state,action):\n",
    "        i = state[0]\n",
    "        j = state[1]\n",
    "        if action == 'S': # south\n",
    "            if i == self.K-1:\n",
    "                return None\n",
    "            else:\n",
    "                i+=1        \n",
    "          \n",
    "        elif action == 'E':#EAST\n",
    "            if j == self.K-1:\n",
    "                return None\n",
    "            else:\n",
    "                j+=1\n",
    "                        \n",
    "        elif action == 'N':#north\n",
    "            if i == 0:\n",
    "                return None\n",
    "            else:\n",
    "                i-=1\n",
    "                                      \n",
    "        elif action == 'W':#WEST\n",
    "            if j == 0:\n",
    "                return None\n",
    "            else:\n",
    "                j-=1\n",
    "            \n",
    "        return (i,j)\n",
    "    \n",
    "    def getPossibleActions(self, state):\n",
    "        \n",
    "        if state[0]==0:\n",
    "            if state[1]==0:\n",
    "                return ['E','S']\n",
    "            elif state[1]==self.K-1:\n",
    "                return ['S','W']\n",
    "            else:\n",
    "                return ['W','E','S']\n",
    "\n",
    "        elif state[0]==self.K - 1:\n",
    "            if state[1]==0:\n",
    "                return ['N','E']\n",
    "            elif state[1]==self.K-1:\n",
    "                return ['T']\n",
    "            \n",
    "            else:\n",
    "                return ['N','E','W']\n",
    "\n",
    "        elif state[1]==0:\n",
    "            return ['S','N','E']\n",
    "        \n",
    "        elif state[1]==self.K-1:\n",
    "            return ['N','S','W']\n",
    "\n",
    "        else:\n",
    "            return ['N','E','S','W']\n",
    "        \n",
    "    def get_best_action(self,d,val):\n",
    "        for key, value in d.items():\n",
    "#             print(\"the dict\",d)\n",
    "            if val == value:\n",
    "#                 print(\"the action chosen\",key)\n",
    "                return key\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8524daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = Grid_ep(k)\n",
    "action_value_state,policy = grid.q()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1df85b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['E', 'E', 'S', 'E', 'E', 'S', 'S', 'S', 'E', 'E', 'S', 'W'],\n",
       " ['E', 'S', 'E', 'E', 'E', 'E', 'S', 'S', 'E', 'S', 'S', 'W'],\n",
       " ['E', 'E', 'S', 'E', 'E', 'E', 'S', 'W', 'S', 'S', 'S', 'S'],\n",
       " ['E', 'E', 'S', 'N', 'S', 'S', 'S', 'E', 'S', 'S', 'S', 'S'],\n",
       " ['N', 'W', 'E', 'S', 'S', 'S', 'S', 'N', 'E', 'E', 'S', 'S'],\n",
       " ['E', 'S', 'N', 'S', 'E', 'S', 'E', 'E', 'E', 'E', 'S', 'S'],\n",
       " ['E', 'S', 'E', 'S', 'W', 'S', 'E', 'E', 'S', 'N', 'S', 'S'],\n",
       " ['S', 'E', 'E', 'S', 'E', 'E', 'E', 'S', 'E', 'E', 'E', 'S'],\n",
       " ['S', 'N', 'E', 'S', 'W', 'E', 'E', 'S', 'N', 'E', 'S', 'S'],\n",
       " ['E', 'E', 'S', 'W', 'E', 'S', 'S', 'S', 'W', 'S', 'S', 'S'],\n",
       " ['E', 'E', 'E', 'S', 'E', 'E', 'S', 'E', 'E', 'E', 'E', 'S'],\n",
       " ['E', 'N', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'T']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3d4f5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting from (10, 0) follow this path\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['E', 'E', 'E', 'S', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'T']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_policy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
