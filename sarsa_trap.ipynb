{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "113e7a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "259c4b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stateClass:\n",
    "    def __init__(self,state, K, reward = -1):\n",
    "        self.K = K\n",
    "        self.Trap_y1 = [1,2,3,4,5,6,7,8]\n",
    "        self.Trap_x1 = [4]\n",
    "        self.Trap_y2 = [5,6,7,8,9,10,11,12]\n",
    "        self.Trap_x2 = [8]\n",
    "        self.isStart = self.isStart(state)\n",
    "        self.isEnd = self.isTerminal(state)\n",
    "        self.state = state\n",
    "        self.reward = reward\n",
    "    \n",
    "        if (self.state == (self.K-1,self.K-1)):\n",
    "            self.reward = 2*(self.K-1)\n",
    "        elif ((self.state[0] in self.Trap_x1 and self.state[1] in self.Trap_y1) or (self.state[0] in self.Trap_x2 and self.state[1] in self.Trap_y2)):\n",
    "            self.reward = -2*(self.K-1)\n",
    "            \n",
    "    def isTerminal(self, state):\n",
    "        if (state==(self.K-1,self.K-1)):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def isStart(self, state):\n",
    "        if (state==(0,0)):\n",
    "            return True\n",
    "        return False\n",
    "      \n",
    "    def getStates(self):\n",
    "        return (self.state[0],self.state[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2750e7bf",
   "metadata": {},
   "source": [
    "# epsilon greedy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bc55335",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grid_ep():\n",
    "    def __init__(self,K):\n",
    "        self.K = K\n",
    "        self.action_value_state = np.zeros((self.K,self.K))\n",
    "        self.policy = [[\"\" for i in range(self.K)] for i in range(self.K)]\n",
    "        \n",
    "    def sarsa(self, alpha=0.01, num_episodes=1500, gamma=0.9,epsilon=0.1):\n",
    "        for ep in range(num_episodes):\n",
    "            init = [i for i in range(self.K)]\n",
    "            m = random.choice(init)\n",
    "            n = random.choice(init)\n",
    "            state=stateClass((m,n),self.K)\n",
    "            if ((state.getStates()[0] in state.Trap_x1 and state.getStates()[1] in state.Trap_y1) or (state.getStates()[0] in state.Trap_x2 and state.getStates()[1] in state.Trap_y2)):\n",
    "                continue\n",
    "            action = self.take_epsilon_greedy_action(state.getStates(),gamma,epsilon)\n",
    "            while True:\n",
    "                next_state = self.step(state.getStates(),action)\n",
    "                if ((next_state[0] in state.Trap_x1 and next_state[1] in state.Trap_y1) or (next_state[0] in state.Trap_x2 and next_state[1] in state.Trap_y2)):\n",
    "                    break\n",
    "                next_state_ = stateClass(next_state,self.K)\n",
    "                reward = next_state_.reward\n",
    "                next_action = self.take_epsilon_greedy_action(next_state,gamma, epsilon)\n",
    "\n",
    "                self.action_value_state[state.getStates()[0]][state.getStates()[1]] += alpha*(reward+gamma*self.action_value_state[next_state[0]][next_state[1]]-self.action_value_state[state.getStates()[0]][state.getStates()[1]])\n",
    "                self.policy[state.getStates()[0]][state.getStates()[1]] = action\n",
    "                state=next_state_\n",
    "                action = next_action\n",
    "                if next_action == 'T':\n",
    "                    break\n",
    "\n",
    "        return self.action_value_state,self.policy\n",
    "\n",
    "    \n",
    "    def take_epsilon_greedy_action(self,state, gamma,epsilon):\n",
    "        if np.random.random() <= epsilon:\n",
    "            return random.choice(self.getPossibleActions(state))\n",
    "        else:\n",
    "\n",
    "            dct={}\n",
    "            possible_actions = self.getPossibleActions(state)\n",
    "            for i, val in enumerate(possible_actions):\n",
    "                if val == ['T']:\n",
    "                    continue\n",
    "                next_state = self.step(state,val)\n",
    "                v_next = self.action_value_state[next_state[0]][next_state[1]]\n",
    "                next_state = stateClass((next_state[0],next_state[1]),self.K)\n",
    "                reward = next_state.reward\n",
    "                v_new = reward + gamma*v_next\n",
    "                dct[val]=v_new\n",
    "\n",
    "            valist = [val for val in dct.values()]\n",
    "            max_value = max(valist)\n",
    "            self.action_value_state[state[0]][state[1]] = max_value\n",
    "            best_action = self.get_best_action(dct,max_value)\n",
    "            return best_action\n",
    "\n",
    "\n",
    "    def step(self, state,action):\n",
    "        i = state[0]\n",
    "        j = state[1]\n",
    "        if action == 'S': # SOUTH\n",
    "            if i == self.K-1:\n",
    "                return None\n",
    "            else:\n",
    "                i+=1        \n",
    "          \n",
    "        elif action == 'E':#EAST\n",
    "            if j == self.K-1:\n",
    "                return None\n",
    "            else:\n",
    "                j+=1\n",
    "                        \n",
    "        elif action == 'N':#NORTH\n",
    "            if i == 0:\n",
    "                return None\n",
    "            else:\n",
    "                i-=1\n",
    "                                      \n",
    "        elif action == 'W':#WEST\n",
    "            if j == 0:\n",
    "                return None\n",
    "            else:\n",
    "                j-=1\n",
    "            \n",
    "        return (i,j)\n",
    "    \n",
    "    def getPossibleActions(self, state):\n",
    "        \n",
    "        if state[0]==0:\n",
    "            if state[1]==0:\n",
    "                return ['E','S']\n",
    "            elif state[1]==self.K-1:\n",
    "                return ['S','W']\n",
    "            else:\n",
    "                return ['W','E','S']\n",
    "\n",
    "        elif state[0]==self.K - 1:\n",
    "            if state[1]==0:\n",
    "                return ['N','E']\n",
    "            elif state[1]==self.K-1:\n",
    "                return ['T']\n",
    "            \n",
    "            else:\n",
    "                return ['N','E','W']\n",
    "\n",
    "        elif state[1]==0:\n",
    "            return ['S','N','E']\n",
    "        \n",
    "        elif state[1]==self.K-1:\n",
    "            return ['N','S','W']\n",
    "\n",
    "        else:\n",
    "            return ['N','E','S','W']\n",
    "        \n",
    "    def get_best_action(self,d,val):\n",
    "        for key, value in d.items():\n",
    "#             print(\"the dict\",d)\n",
    "            if val == value:\n",
    "#                 print(\"the action chosen\",key)\n",
    "                return key\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4be9648c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter k the size of the gridWorld: 12\n"
     ]
    }
   ],
   "source": [
    "k = int(input(\"Enter k the size of the gridWorld: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c710128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = Grid_ep(k)\n",
    "action_value_state,policy = grid.sarsa(gamma = 0.9,epsilon = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72711db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['S', 'W', 'W', 'S', 'W', 'S', 'S', 'E', 'S', 'S', 'S', 'S'],\n",
       " ['S', 'S', 'W', 'W', 'S', 'S', 'S', 'S', 'E', 'S', 'W', 'W'],\n",
       " ['S', 'S', 'S', 'W', 'W', 'E', 'S', 'S', 'E', 'S', 'S', 'W'],\n",
       " ['S', 'W', 'W', 'W', 'W', 'E', 'E', 'E', 'E', 'S', 'W', 'W'],\n",
       " ['S', '', '', '', '', '', '', '', '', 'S', 'W', 'W'],\n",
       " ['S', 'E', 'S', 'E', 'S', 'S', 'E', 'S', 'S', 'W', 'E', 'S'],\n",
       " ['S', 'W', 'S', 'S', 'S', 'S', 'W', 'S', 'W', 'W', 'S', 'W'],\n",
       " ['S', 'S', 'E', 'E', 'S', 'W', 'W', 'W', 'W', 'W', 'W', 'W'],\n",
       " ['S', 'S', 'S', 'E', 'S', '', '', '', '', '', '', ''],\n",
       " ['E', 'S', 'E', 'E', 'E', 'E', 'E', 'E', 'S', 'W', 'E', 'S'],\n",
       " ['E', 'S', 'E', 'S', 'S', 'E', 'S', 'N', 'E', 'S', 'N', 'S'],\n",
       " ['E', 'E', 'N', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'T']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "454b3650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_policy():\n",
    "    m = int(input(\"Entrer la ligne: \"))\n",
    "    n = int(input(\"Entrer la colonne: \"))\n",
    "    while(m in [4] and n in [1,2,3,4,5,6,7,8] or m in[8] and n in [5,6,7,8,9,10,11,12]):\n",
    "        m = int(input(\"Entrer la ligne: \"))\n",
    "        n = int(input(\"Entrer la colonne: \"))\n",
    "    l = []\n",
    "    start = (m,n)\n",
    "    print(f\"starting from {start} follow this path\")\n",
    "    l.append(policy[m][n])\n",
    "    while(policy[m][n]!='T'):\n",
    "        if policy[m][n]=='E':\n",
    "            n+=1\n",
    "            l.append(policy[m][n])\n",
    "        elif policy[m][n]=='W':\n",
    "            n-=1\n",
    "            l.append(policy[m][n])\n",
    "        elif policy[m][n]=='S':\n",
    "            m+=1\n",
    "            l.append(policy[m][n])\n",
    "        elif policy[m][n]=='N':\n",
    "            m-=1\n",
    "            l.append(policy[m][n])\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba9bd9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrer la ligne: 1\n",
      "Entrer la colonne: 2\n",
      "starting from (1, 2) follow this path\n",
      "['S', 'W', 'S', 'W', 'S', 'S', 'E', 'E', 'E', 'E', 'S', 'S', 'S', 'S', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'S', 'S', 'T']\n"
     ]
    }
   ],
   "source": [
    "road = print_policy()\n",
    "print(road)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cec56b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['S', 'W', 'W', 'W', 'W', 'S', 'S', 'S', 'S', 'S', 'S', 'S'],\n",
       " ['S', 'W', 'S', 'N', 'N', 'S', 'E', 'S', 'S', 'S', 'W', 'S'],\n",
       " ['S', 'S', 'W', 'W', 'W', 'W', 'E', 'S', 'S', 'S', 'S', 'S'],\n",
       " ['S', 'W', 'W', 'W', 'W', 'W', 'E', 'E', 'E', 'S', 'S', 'S'],\n",
       " ['S', '', '', '', '', '', '', '', '', 'S', 'W', 'W'],\n",
       " ['E', 'E', 'E', 'E', 'S', 'W', 'S', 'S', 'S', 'S', 'S', 'S'],\n",
       " ['S', 'S', 'E', 'E', 'S', 'S', 'S', 'S', 'S', 'W', 'W', 'W'],\n",
       " ['E', 'E', 'E', 'E', 'S', 'W', 'W', 'W', 'W', 'N', 'W', 'N'],\n",
       " ['S', 'N', 'S', 'E', 'S', '', '', '', '', '', '', ''],\n",
       " ['E', 'E', 'S', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'S'],\n",
       " ['S', 'S', 'E', 'E', 'E', 'E', 'E', 'S', 'N', 'E', 'E', 'S'],\n",
       " ['E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'T']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab54126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528bc3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a2e2618",
   "metadata": {},
   "source": [
    "# greedy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72ef41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grid():\n",
    "    def __init__(self,K):\n",
    "        self.K = K\n",
    "#         self.grid = np.zeros((self.K,self.K))\n",
    "        self.action_value_state = np.zeros((self.K,self.K))\n",
    "#         self.policy = np.chararray((self.K,self.K)).decode(\"utf-8\")\n",
    "        self.policy = [[\"\" for i in range(self.K)] for i in range(self.K)]\n",
    "        \n",
    "    def sarsa(self, alpha=0.01, num_episodes=1500, gamma=0.9):\n",
    "        for ep in range(num_episodes):\n",
    "            init = [i for i in range(self.K)]\n",
    "            m = random.choice(init)\n",
    "            n = random.choice(init)\n",
    "            state=stateClass((m,n),self.K)\n",
    "            if ((state.getStates()[0] in state.Trap_x1 and state.getStates()[1] in state.Trap_y1) or (state.getStates()[0] in state.Trap_x2 and state.getStates()[1] in state.Trap_y2)):\n",
    "                continue\n",
    "            action = self.take_greedy_action(state.getStates())\n",
    "            while True:\n",
    "                next_state = self.step(state.getStates(),action)\n",
    "                if ((next_state[0] in state.Trap_x1 and next_state[1] in state.Trap_y1) or (next_state[0] in state.Trap_x2 and next_state[1] in state.Trap_y2)):\n",
    "                    break\n",
    "                next_state_ = stateClass(next_state,self.K)\n",
    "                reward = next_state_.reward\n",
    "                next_action = self.take_greedy_action(next_state)\n",
    "#                 print(\"next state \",next_state)\n",
    "#                 print(f\"the actual action is {action} and the nexte one is {next_action}\")\n",
    "                self.action_value_state[state.getStates()[0]][state.getStates()[1]] += alpha*(reward+gamma*self.action_value_state[next_state[0]][next_state[1]]-self.action_value_state[state.getStates()[0]][state.getStates()[1]])\n",
    "                self.policy[state.getStates()[0]][state.getStates()[1]] = action\n",
    "                state=next_state_\n",
    "                action = next_action\n",
    "                if next_action == 'T':\n",
    "                    break\n",
    "\n",
    "        return self.action_value_state,self.policy\n",
    "\n",
    "    def take_greedy_action(self,state, gamma=0.9):\n",
    "        dct={}\n",
    "        possible_actions = self.getPossibleActions(state)\n",
    "        for i, val in enumerate(possible_actions):\n",
    "            if val == ['T']:\n",
    "                continue\n",
    "            next_state = self.step(state,val)\n",
    "            v_next = self.action_value_state[next_state[0]][next_state[1]]\n",
    "            next_state = stateClass((next_state[0],next_state[1]),self.K)\n",
    "            reward = next_state.reward\n",
    "            v_new = reward + gamma*v_next\n",
    "            dct[val]=v_new\n",
    "\n",
    "        valist = [val for val in dct.values()]\n",
    "        max_value = max(valist)\n",
    "        self.action_value_state[state[0]][state[1]] = max_value\n",
    "        best_action = self.get_best_action(dct,max_value)\n",
    "        return best_action\n",
    "\n",
    "\n",
    "    def step(self, state,action):\n",
    "        i = state[0]\n",
    "        j = state[1]\n",
    "        if action == 'S': # NORTH\n",
    "            if i == self.K-1:\n",
    "                return None\n",
    "            else:\n",
    "                i+=1        \n",
    "          \n",
    "        elif action == 'E':#EAST\n",
    "            if j == self.K-1:\n",
    "                return None\n",
    "            else:\n",
    "                j+=1\n",
    "                        \n",
    "        elif action == 'N':#SUD\n",
    "            if i == 0:\n",
    "                return None\n",
    "            else:\n",
    "                i-=1\n",
    "                                      \n",
    "        elif action == 'W':#WEST\n",
    "            if j == 0:\n",
    "                return None\n",
    "            else:\n",
    "                j-=1\n",
    "            \n",
    "        return (i,j)\n",
    "    \n",
    "    def getPossibleActions(self, state):\n",
    "        \n",
    "        if state[0]==0:\n",
    "            if state[1]==0:\n",
    "                return ['E','S']\n",
    "            elif state[1]==self.K-1:\n",
    "                return ['S','W']\n",
    "            else:\n",
    "                return ['W','E','S']\n",
    "\n",
    "        elif state[0]==self.K - 1:\n",
    "            if state[1]==0:\n",
    "                return ['N','E']\n",
    "            elif state[1]==self.K-1:\n",
    "                return ['T']\n",
    "            \n",
    "            else:\n",
    "                return ['N','E','W']\n",
    "\n",
    "        elif state[1]==0:\n",
    "            return ['S','N','E']\n",
    "        \n",
    "        elif state[1]==self.K-1:\n",
    "            return ['N','S','W']\n",
    "\n",
    "        else:\n",
    "            return ['N','E','S','W']\n",
    "        \n",
    "    def get_best_action(self,d,val):\n",
    "        for key, value in d.items():\n",
    "#             print(\"the dict\",d)\n",
    "            if val == value:\n",
    "#                 print(\"the action chosen\",key)\n",
    "                return key\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5551a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = Grid(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d7aa602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_value_state,policy = grid.sarsa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d46909ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['S', 'W', 'W', 'W', 'W', 'W', 'E', 'E', 'E', 'S', 'W', 'S'],\n",
       " ['S', 'S', 'S', 'S', 'S', 'E', 'E', 'E', 'E', 'S', 'S', 'S'],\n",
       " ['S', 'S', 'S', 'S', 'S', 'E', 'E', 'E', 'E', 'S', 'S', 'S'],\n",
       " ['S', 'W', 'W', 'W', 'W', 'E', 'E', 'E', 'E', 'S', 'S', 'S'],\n",
       " ['S', '', '', '', '', '', '', '', '', 'S', 'S', 'S'],\n",
       " ['S', 'E', 'E', 'E', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S'],\n",
       " ['S', 'E', 'E', 'E', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S'],\n",
       " ['S', 'E', 'E', 'E', 'S', 'W', 'W', 'W', 'W', 'W', 'W', 'W'],\n",
       " ['S', 'E', 'E', 'E', 'S', '', '', '', '', '', '', ''],\n",
       " ['S', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'S'],\n",
       " ['E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'S'],\n",
       " ['N', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'T']]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4012ea5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrer la ligne: 3\n",
      "Entrer la colonne: 3\n",
      "starting from (3, 3) follow this path\n",
      "['W', 'W', 'W', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'S', 'T']\n"
     ]
    }
   ],
   "source": [
    "road = print_policy()\n",
    "print(road)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b617c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
